llm:
  provider: openrouter         # Options: ollama, openai, openrouter, groq, etc.
  model: google/gemini-2.0-flash-001  # Model name for the selected provider
  context_length: 60000    # Some models support higher limitsm
# ollama:
#   host: http://host.docker.internal:11434

# Notes:
# - To switch models or providers, edit the values above
# - You can add future providers (e.g., openai, anthropic) here under `llm`
# - Providers currently supported: groq, ollama, openai, openrouter
  # model: anthropic/claude-sonnet-4  # Model name for the selected provider
# 